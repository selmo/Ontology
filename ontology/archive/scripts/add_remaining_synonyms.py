#!/usr/bin/env python3
"""
Add synonyms to the remaining 18 terms without synonyms
"""

import json
from datetime import datetime

# Synonyms for the remaining 18 terms
REMAINING_SYNONYMS = {
    # 09. ë¬¸í™”ê´€ê´‘ (5ê°œ)
    'T09050001': ['ì²´ìœ¡ì¸í”„ë¼', 'ìš´ë™ì‹œì„¤', 'ìŠ¤í¬ì¸ ì„¼í„°'],
    'T09050002': ['í”„ë¡œë¦¬ê·¸', 'ì§ì—…ìŠ¤í¬ì¸ ', 'í”„ë¡œê²½ê¸°'],
    'T09050003': ['ìƒí™œìŠ¤í¬ì¸ ', 'ì—¬ê°€ì²´ìœ¡', 'ë™í˜¸íšŒì²´ìœ¡'],
    'T09060001': ['ë°©ì†¡í”„ë¡œê·¸ë¨', 'ë¯¸ë””ì–´ì½˜í…ì¸ ', 'TVì½˜í…ì¸ '],
    'T09060002': ['ì˜¨ë¼ì¸ë™ì˜ìƒì„œë¹„ìŠ¤', 'ìŠ¤íŠ¸ë¦¬ë°ì„œë¹„ìŠ¤', 'ë„·í”Œë¦­ìŠ¤'],

    # 02. êµìœ¡ (4ê°œ)
    'T02050001': ['ìœ ì•„êµìœ¡ê¸°ê´€', 'ì–´ë¦°ì´ì§‘', 'ìœ ì¹˜ì›'],
    'T02050002': ['ëˆ„ë¦¬êµìœ¡ê³¼ì •', 'êµ­ê°€ìˆ˜ì¤€êµìœ¡ê³¼ì •'],
    'T02060001': ['íŠ¹ìˆ˜í•™êµ', 'ì¥ì• ì¸êµìœ¡', 'íŠ¹ìˆ˜êµìœ¡ê¸°ê´€'],
    'T02060002': ['ì˜ì¬êµìœ¡ì›', 'ì˜ì¬í•™ê¸‰', 'ì˜ì¬í•™ìƒ'],

    # 05. ë²•ë¥  (3ê°œ)
    'T05040005': ['êµ­ì„¸ì²­ì„¸ê¸ˆ', 'êµ­ê°€ì„¸ìˆ˜'],
    'T05040006': ['ì§€ë°©ì„¸ë¬´', 'ìì¹˜ë‹¨ì²´ì„¸ê¸ˆ'],
    'T05060002': ['í–‰ì •ìŸì†¡', 'í–‰ì •ë¶ˆë³µ'],

    # 10. í™˜ê²½ê¸°ìƒ (2ê°œ)
    'T10060001': ['ìì›ì¬í™œìš©', 'íê¸°ë¬¼ì¬ìƒ', 'ì¬ì‚¬ìš©'],
    'T10060002': ['ìˆœí™˜ìì›ê²½ì œ', 'ìì›ìˆœí™˜'],

    # 01. ê³µê³µí–‰ì • (1ê°œ)
    'T01040002': ['êµ­ë¯¼ì„œë¹„ìŠ¤', 'í–‰ì •ì„œë¹„ìŠ¤', 'ë¯¼ì›ì„œë¹„ìŠ¤'],

    # 07. ì‚°ì—…ê²½ì œ (1ê°œ)
    'T07070003': ['ë¬´ì—­ì ì', 'ë¬´ì—­í‘ì', 'ìˆ˜ì¶œì…ì°¨ì•¡'],

    # 11. ê³¼í•™ê¸°ìˆ  (1ê°œ)
    'T11060001': ['ìš°ì£¼í•­ê³µ', 'ìš°ì£¼ê¸°ìˆ ', 'í•­ê³µìš°ì£¼'],

    # 12. ì¬ë‚œì•ˆì „ (1ê°œ)
    'T12040005': ['ê³ ì˜¨íŠ¹ë³´', 'í­ì—¼ì£¼ì˜ë³´', 'ì—´ëŒ€ì•¼'],
}


def add_remaining_synonyms(input_file='ontology.json', output_file='ontology.json'):
    """Add synonyms to remaining terms"""

    print(f"Loading {input_file}...")
    with open(input_file, 'r', encoding='utf-8') as f:
        data = json.load(f)

    # Statistics
    added_count = 0
    updated_terms = []

    # Process each domain
    for domain in data['domains']:
        for term in domain.get('terms', []):
            term_id = term['id']

            if term_id in REMAINING_SYNONYMS:
                new_synonyms = REMAINING_SYNONYMS[term_id]
                existing_synonyms = term.get('synonyms', [])

                # Add new synonyms (avoid duplicates)
                for syn in new_synonyms:
                    if syn not in existing_synonyms:
                        existing_synonyms.append(syn)
                        added_count += 1

                term['synonyms'] = existing_synonyms
                updated_terms.append({
                    'id': term_id,
                    'name': term['name_ko'],
                    'domain': domain['code'],
                    'domain_name': domain['name_ko'],
                    'total': len(existing_synonyms)
                })

    # Update metadata description
    data['metadata']['description'] = 'MC ë¶„ë¥˜Â·ìš©ì–´ í†µí•© ì²´ê³„ (ë™ì˜ì–´ ëŒ€í­ í™•ì¥: 87 â†’ 450+, ì»¤ë²„ë¦¬ì§€ 100%)'

    # Save
    print(f"Saving to {output_file}...")
    with open(output_file, 'w', encoding='utf-8') as f:
        json.dump(data, f, ensure_ascii=False, indent=2)

    # Print report
    print("\n" + "=" * 80)
    print("ë‚˜ë¨¸ì§€ ë™ì˜ì–´ ì¶”ê°€ ì™„ë£Œ")
    print("=" * 80)
    print(f"ì´ ì¶”ê°€ëœ ë™ì˜ì–´ ìˆ˜: {added_count}")
    print(f"ì—…ë°ì´íŠ¸ëœ ìš©ì–´ ìˆ˜: {len(updated_terms)}")

    print(f"\në„ë©”ì¸ë³„ ì¶”ê°€ ë‚´ì—­:")
    print("-" * 80)

    # Group by domain
    from collections import defaultdict
    domain_stats = defaultdict(lambda: {'count': 0, 'terms': []})

    for term_info in updated_terms:
        domain_code = term_info['domain']
        domain_stats[domain_code]['count'] += (term_info['total'] - len(REMAINING_SYNONYMS[term_info['id']]) + len(REMAINING_SYNONYMS[term_info['id']]))
        domain_stats[domain_code]['terms'].append(term_info)

    for domain_code in sorted(domain_stats.keys()):
        stats = domain_stats[domain_code]
        domain_name = stats['terms'][0]['domain_name'] if stats['terms'] else ''
        print(f"\n{domain_code}. {domain_name} ({len(stats['terms'])}ê°œ ìš©ì–´)")
        for term in stats['terms']:
            print(f"  {term['id']}: {term['name']} â†’ {term['total']}ê°œ ë™ì˜ì–´")

    return added_count, len(updated_terms)


if __name__ == '__main__':
    added, updated = add_remaining_synonyms()
    print(f"\nâœ… ì™„ë£Œ: {added}ê°œ ë™ì˜ì–´ê°€ {updated}ê°œ ìš©ì–´ì— ì¶”ê°€ë¨")
    print("ğŸ¯ ëª©í‘œ: 100% ì»¤ë²„ë¦¬ì§€ ë‹¬ì„±!")
